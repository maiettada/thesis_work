% !TEX encoding = IsoLatin 

% Affinché gli accenti vengano accettati, assicurati che la codifica di questo file
% sia ISO 8859-1

% PER OTTENERE IL PDF, digitare da terminale
% ./makepdfplease
% 

\chapter[Realizzazione dei prototipi][]{4. Realizzazione dei prototipi}

In questa sezione andremo a illustrare come sono stati realizzati i due approcci di Named Entity Recognition.
Un primo prototipo è stato realizzato infatti con le tradizionali tecniche di programmazione e con l'uso di espressioni regolari.
Il secondo prototipo invece è stato realizzato con tecniche di Machine Learning.

\section{Espressioni regolari}
Il prototipo in questione ha come obiettivo la ricerca di attestazioni SOA all'interno di un testo. Nello specifico, il prototipo adopera tecniche di programmazione tradizionale, usando degli script Python ed effettuando ricerche di stringhe con espressioni regolari

\paragraph{Formulazione del problema:}
\textit{
Dato un insieme di documenti in formato testuale appartenenti al dominio delle gare d'appalto, estrarre le attestazioni SOA ivi menzionate.
}

\section{Accesso ai documenti del dataset}

Il dataset dei documenti di gare d'appalto è implementato con un file csv. 
Tale file dunque descrive ogni documento come campi comma-separated; alcuni di questi campi sono l'id del documento, il testo del documento, il cig del bando, lo score della classificazione.
Per l'acquisizione di dati si è adoperata la libreria Pandas: questa consente di convertire i dati testuali comma-separated in un apposito oggetto Pandas Dataframe.
%id_file,testo,concat,m_autore,m_data_creazione,m_data_ultima_modifica,m_pagine,numero_cig,id_tipo,score_classificazione,tipo
\begin{Verbatim}
dataframe = pd.read_csv(filepath, sep=',')
\end{Verbatim}

Una volta importato il csv in un dataframe, accediamo al dataframe esattamente come se fosse una matrice; di seguito il codice per stampare il primo elemento del campo testo:

\begin{Verbatim}
print(dataframe['testo'][0])
\end{Verbatim}

Una volta estratti gli elementi di testo del dataframe, possiamo applicare le espressioni regolari alla ricerca delle attestazioni SOA su ogni singolo testo.

\section{Raccolta e filtraggio di istanze}
L'individuazione e la classificazione di attestazioni SOA da un testo richiedono due azioni: 
\begin{enumerate}
\item Raccolta delle istanze: trovare una porzione di testo che abbia la struttura di un valore SOA;
\item Filtraggio delle istanze: verificare che quel dato corrisponda ad una attestazione SOA valida.
\end{enumerate}
Per dare un esempio, posso coprire la prima azione con una regex minimale che descriva la categoria come \say{OS} seguito da due cifre:
 
\begin{Verbatim}
regex_categoria = r'O(S|G)(\d\d?)'
\end{Verbatim}

Ciò non ci assicura di avere una categoria valida: ad esempio OS99 fa match con la regex,
ma non è una categoria valida, poiché le opere specialistiche si fermano alla OS35.
Similmente, le opere generali si fermano alla OG13; la regex banale mostrata in quest'ipotesi cattura benissimo un'istanza di testo come \say{OG14}, che però non esiste nell'insieme delle categorie.
La seconda azione consiste quindi nel verificare l'esistenza della stringa nell'insieme Categorie e in tal caso classificarla come tale.

L'ultimo punto da introdurre è la normalizzazione delle istanze individuate:
è infatti possibile che l'entità \say{Opera Specialistica numero 1} abbia in pratica scritture diverse, come \say{OS1}, \say{O.S.1}, \say{O.S.-1} e così via, a seconda dello stile di scrittura di chi ha redatto un documento. Per quanto una buona regex possa raccogliere tutte queste istanze e pur essendo tutte queste istanze valide, il prototipo in questione darà ai dati individuati una forma \textbf{normalizzata} ovvero standardizzata.

Infine la procedura svolta è descrivibile a grandi linee come segue:
\begin{enumerate}
\item Nei punti di interesse, si individua una porzione di testo o \textit{finestra}, all'interno della quale si cercano le attestazioni;
\item internamente alla finestra si applicano le espressioni regolari relative a categoria SOA e classifica SOA;
\item i risultati trovati vengono posti in una forma standard o \textit{normalizzata} e filtrati rispetto al dizionario dei valori SOA. 
\end{enumerate}




\section{Ricerca e classificazione delle attestazioni SOA}
Analizzando un documento testuale, possiamo con poche regex raccogliere la maggior parte dei dati di nostro interesse.
I dati \acrshort{societa-soa} precedentemente illustrati hanno infatti una certa regolarità nei nomi:
per raccogliere le categorie, ci basterà trovare tutte le parole aventi per prefissi \say{OS} e \say{OG}; non tutte le
parole contenenti questi due prefissi sono automaticamente dati SOA, ma partiamo da questi match per isolare delle porzioni di testo che costituiranno le \textit{finestre d'interesse} da verificare.
In tali finestre andremo a verificare che i dati descrivano effettivamente delle sigle SOA e andremo a cercare le
classifiche economiche.
Schematizziamo di seguito il funzionamento dell'estrazione dati e classificazione con regex.

	\begin{figure}[ht]
	\includegraphics[scale=0.50]{regex_complete.png}
	\caption{Human In The Loop framework} % caption
		%\label{fig:diagram}             % for referencing of figure, key select as you wish
	\end{figure}
	

\begin{comment}
\item identifico una finestra di testo di mio interesse; 
\item all'interno della finestra ricerco istanze delle singole categorie e classifiche;
\item per ogni categoria c individuata, effettuo la normalizzazione normalised\_category(c),
   per cui di quella categoria verrà preso il nome standard;
   ad esempio normalised\_category(\say{og1})  e  normalised\_category(\say{OG 1}) restituiranno entrambe il valore normalizzato \say{OG-1};
\item effettuo un filtraggio sulle categorie finora ottenute:
   se, ad esempio, la regex ammette una categoria come \say{OS-99}, questa non fa parte della lista di categorie SOA "conosciute"   e viene dunque rigettata;
\item effettuo una normalizzazione delle classifiche economiche;
\item concateno categoria SOA e classifica economica trovata; dunque ho a disposizione l'attestazione per intero;
\item per ogni "finestra" di testo, raccolgo le attestazioni individuate e relativi offset (start\_offset, end\_offset) interni al documento;
\item Scrivo l'ouput in un apposito file csv. Per ogni finestra di testo,
   stampo istanze SOA individuate e relative coppie (start\_offset, end\_offset).
\end{comment}



L'output di questo prototipo-regex mostra delle limitazioni e dei casi tipici di errore:
in alcune istanze testuali può capitare che una categoria sia menzionata con un nome leggermente diverso da quello canonico (ad es. \say{OS-18}, laddove le alternative accettabili sono \say{OS-18A} e \say{OS-18B}).
In questi casi il filtering, la normalizzazione e anche le regex possono essere leggermente modificate per riconoscere come accettabili tali valori testuali; però modifiche ripetute alle regex possono portare le stesse a diventare incomprensibili e ad essere error-prone.

In definitiva, le regex hanno il vantaggio di produrre dei risultati immediati, ma non molto adatti a testi troppo variegati.
Di seguito forniamo una visione più dettagliata sulle regex usate relativamente alle categorie e alle classifiche economiche.

\newpage

\section{Finestre, espressioni regolari, filtering}

La Finestra di caratteri è selezionata nel modo seguente:
la presenza di una delle stringhe \{ \say{OS}, \say{Os}, \say{OG}, \say{Og} \} costituisce l'inizio della finestra;
successivamente vengono selezionati 100 caratteri.
Regex adoperata:
\begin{Verbatim}
from_os_n_char = r'O(S|G|s|g).{1,100}'
\end{Verbatim}

Ricerca  delle categorie SOA operata internamente alla finestra:
la presenza di una delle stringhe \{ \say{OS}, \say{Os}, \say{OG}, \say{Og} \} costituisce l'inizio della presunta attestazione;
la stringa deve continuare con un separatore e al più due cifre decimali (ad es. \say{Os-98}, \say{Os-5} )
la stringa può continuare con una lettera, che ci si aspetta essere la sottocategoria \{ \say{A}, \say{B}  \}; ad esempio è accettabile una stringa del tipo \say{OS-18A}.
Con le dovute cautele sui vari tipi di carattere separatore \{\say{-},\say{.}, \} e volendo tollerare eventuali caratteri di andata a capo, ottengo l'espressione regolare:

\begin{Verbatim}
cat\_regex = r'O(S|G|s|g)\n?[-\s]?\n?(\d\d?\w?)'
\end{Verbatim}
 
\paragraph{Normalizzazione delle categorie:}
Viene svolta con regex-substitution;
seleziona la dicitura \{ \say{OS}, \say{Os}, \say{OG}, \say{Og} \} e il gruppo (dd?w?) costituito dal numero e dalla sottocategoria \say{a}/\say{b}.
Ad esempio: le istanze 

\begin{Verbatim}
"OS 10" , "OS<tab>10" e "OS\n10"
\end{Verbatim}
con la normalizzazione assumono la stessa forma \say{OS-10}.


\paragraph{Filtering:} seleziona le attestazioni \textit{sensate} in quanto contenute nel relativo dizionario. È infatti possibile che un'attestazione sia accettabile per la regex (ad es. OS-77) ma non abbia senso nel dominio delle categorie SOA.

\paragraph{Ricerca di classifiche economiche:}
numeri romani;
mi assicuro che le lettere siano effettivamente numeri piuttosto che inizi di parole
(e.g. la \say{I} maiuscola in \say{OS-12 Importo uguale a } non va considerata un match con la
 classifica I )
Regex adoperata:

\begin{Verbatim}
class_regex ='(IV bis|IV|III|II|IX|VIII|VII|VI|X|V|I)[^\w]'
\end{Verbatim}
 



\section{Errori comuni riportati}

Dovendo valutare l'output del prototipo, raccolgo qui gli errori raggruppandoli in alcune categorie principali. 
Dalla tabella contenuta nel  foglio di calcolo condiviso  si possono vedere le corrispondenze tra input e output, compresi i casi di errore.
Per questo report stati considerati i primi 100 elementi della tabella soa.csv


Gli errori riportati sorgono in maniere diverse: alcuni nascono a livello di regex, alcuni casi sono causati dallo script e dal dizionario fissato nello script; altri ancora dipendono da particolarità del documento.

\paragraph{Categoria non riconosciuta:}
\begin{Verbatim}
   riga   657,  OS "I                
   riga 1181, OGI I si ? 105.541,05 | 62,901
   riga 790, OG1IV bis e categoria scorporabile a;
   riga 792, OG1III e categoria scorporabile a;

   riga 130, "OG  11 di cui"; 
   riga 540, OS   21; altre simili: 541,542
   riga 135, "OS 12-A, OS 18-A, OS 21  e  OS  2-A"; altre: 382,487, 1159, 1160,1176,1248;
   riga 143, "OS.2"; altre: 145, 148, 254;
\end{Verbatim}

\textbf{Motivazioni:} 
\begin{enumerate}
\item caratteri estranei a quelli previsti dalla regex;
\item spaziature non previste nella  soa\_cat\_regex;
\item nella  cat\_regex il match avviene correttamente solo con \say{OS-12A}; non è previsto il carattere \say{-} prima della lettera \say{A};
\item nella  cat\_regex non è previsto il carattere di interpunzione \say{.}
\end{enumerate}

\paragraph{Classifica non acquisita:

\begin{Verbatim}
   riga 61, "OS21 nella classe I.";
   riga 124,"OG 3 classifica II;";
   riga 371, "OG 3 classifica I;";
   riga 416, OG 12 III;
   riga 1251, OG 3 classifica V;        
   riga 1262, OG1 Classifica I;
   riga 825,  "OG1 V OS3 VE OS28IV BIS"     
\end{Verbatim}

\textbf{Motivazioni:} 
\begin{enumerate}
\item errore lato script: lo script seleziona una sottostringa con il carattere finale mancante, causando il mancato match con la class\_regex;
\item \say{OS3 VE} (dove VE indica \say{V classifica Economica}) non è previsto dalla regex della classifica.
\end{enumerate}

\paragraph{Sottoclassifica non acquisita:}
  riga 125, "OS21       |IIIBis     |        ", 'OS-21-?';
  riga 127, "OS21    classifica    III   Bis ", ?OS-21-III';
  riga 302, "dunque in class. III-bis", viene assunta classifica III; altre: 305,372,374
  riga 338, "IV-bis" assunto come IV; simili: 339,341,827;

\textbf{Motivazioni:} 
\begin{enumerate}
\item la class\_regex non accetta "IIIBis" come classifica;
\item la class\_regex accetta solo la dicitura "IV bis".
\end{enumerate}

\paragraph{Categorie non riconosciute dal dizionario:}
\begin{Verbatim}
 riga 61, "OS 18", "OS18" e simili; altre istanze simili: 177,183,195
  riga 132, "OS  2"; altre: 134, 147,150,151,248
  riga 131, " OS 12, OS 18,"; altre: 133, 378,379,380,381
  riga 260, "OS12 anziché OS12B in quanto" , OS12 non accettato dal filtering; altre:      265,1253;
  riga 705, ["Os28" si chiede la ], viene estratto Os-28, la "s" minuscola non è accettata dal filtering.
\end{Verbatim}
\paragraph{Motivazioni:} 
Sono considerate valide le forme "OS-2A" e "OS-2B", "OS-12A" e "OS-12B",  "OS-18A" e "OS-18B", "OS-20A" e "OS-20B"; assenti nel dizionario, invece, le categorie prive di specifica A/B ("OS-2", "OS-12", "OS-18", "OS-20").



\paragraph{Valori erronei di classifica economica}
\begin{Verbatim}
1. Numero romano estraneo
   riga 802, "OG1" per l'intero importo dell'appalto (e ovviamente per il Lotto II;
   riga 803, OS14" per il lotto II ;        
   riga 804, OS22" per il lotto III o eventualmente ricorrere ad ATI o avvalimento?;
2. Altre maiuscole non relative a classifica
   riga 1100, "OS13 (S.I.O.S. scorporabile e subappaltabile max 30%)        
3. Caratteri estranei
   riga 828, "OS24 II, OS261 E OS 33 Il) e Visura Camerale e certificazione ISO 9001:2008 ISO 18001:2007       \end{Verbatim}  


\section{Considerazioni}

Gli errori rilevati nell'output - come detto precedentemente - sorgono in diversi punti della logica utilizzata e hanno livelli di problematicità differenti:
\begin{itemize}
\item un bug nello script: se sistematico, può essere corretto facilmente;
\item un valore assente a livello di dizionario: questo comporta delle decisioni sui valori del dominio; se trovo la stringa \say{OS-18},  è sensato supporre che si stia parlando di \say{OS-18A}?  o forse è possibile che l'autore sottointendesse un valore \say{OS-18B} dopo averlo precedentemente menzionato?
\end{itemize}
A livello di regex è possibile apportare modifiche per fare match dei casi più particolari, però si pongono due problemi:
\begin{itemize}
\item  dopo aver adattato la regex ad un nuovo caso particolare, questa potrebbe non accettare alcuni casi che facevano match in precedenza; dunque ad ogni modifica è necessario ricontrollare esaustivamente tutti gli output - compresi quelli che erano processati bene prima delle modifiche;
\item  eccessiva complessità della regex: dopo pochi rimaneggiamenti, l'espressione regolare diventa
tendenzialmente incomprensibile, per cui future correzioni e modifiche diventano più difficili ed error-prone.\end{itemize}
In generale i documenti esaminati usano un linguaggio naturale; è quindi possibile -nonostante la natura tecnica dei discorsi-  che un documento da processare contenga attestazioni SOA trascritte in maniere differenti, non note a priori (Ad es. \say{OS11}, \say{Opere specialistiche, categoria 11}, \say{Op.Sp. 11}), dettate essenzialmente dallo stile dell'autore.


Dunque, in un documento potrebbe esserci una trascrizione nuova da adottare; e l'ideale sarebbe aggiungerla in maniera incrementale alla casistica di trascrizioni già adottate in precedenza.
A livello di regex l'approccio incrementale non è per nulla agevole: si deve scrivere una regex nuova, che aggiunga i nuovi casi rilevati senza compromettere quelli precedenti.
La nuova regex deve essere dunque testata sia sulla casistica di valori nuovi  sia sulla casistica vecchia.
Infine, rimane il problema che la regex non mi consente di delineare un contesto, ad es.:
nella stringa \say{OS14 per il lotto II}  la class\_regex troverà un numero romano (\say{II}, appunto) e lo assumerà erroneamente come valore di classifica.
Risolvere questo singolo caso a livello regex -nello specifico, escludere i numeri romani dopo la parola  \say{lotto}- comporta espressioni regolari più complesse, ma non esclude ulteriori  casi di falso-positivo.


\section{Superare le limitazioni delle regex}
In estrema sintesi, la criticità principale dell'approccio usato è 
affidare il riconoscimento del valore-stringa ad un criterio fissato a priori.
L'approccio ideale dovrebbe consentire all'operatore umano di aggiungere istanze alla casistica già presente, in modo da:
\begin{itemize}
\item avere a disposizione l'interpretazione umana nei casi in cui l'automa riconoscitore della regex fraintenda un input;
\item raccogliere tali istanze in maniera incrementale, in modo che il loro accumularsi costituisca una forma di esperienza applicabile automaticamente ai successivi input.
\end{itemize}

L'esperienza acquisita fondamentalmente permetterebbe di confrontare l'input non con un singolo pattern a priori -che nell'esempio specifico è una regex, ma potrebbe anche essere definito in maniera procedurale- ma con un insieme di più pattern, incrementabili a discrezione dell'operatore umano per catturare anche le istanze meno standardizzabili del linguaggio.

L'approccio del Machine Learning supervisionato consiste nell'usare un algoritmo per produrre un modello che minimizzi 
gli errori di classificazione rispetto a delle classificazioni vere per ipotesi.
Questo ha una conseguenza importante: un classificatore, una volta istruito a riconoscere una classe
partendo da una certa quantità di esempi giusti, potrà stimare la classe anche in presenza di dati 
non uguali agli esempi di partenza.
Ciò costituisce una grande differenza rispetto alla regex, che consente di rilevare un testo
solo se esattamente conforme all'automa da essa descritto.

\section{Annotazioni gold in Doccano}
Per poter applicare l'approccio ML alla ricerca di attestazioni SOA è necessario raccogliere le cosiddette
\say{annotazioni gold} per costruire la \textbf{Ground Truth}  sulla quale basare l'apprendimento della rete neurale.
I dati SOA, provenendo da un linguaggio formale e burocratico, non sono scritti in maniera uguale in tutti i documenti ma soffrono
di una forte variabilità.
Vogliamo dare un'idea di quanti modi diversi esistono per indicare una categoria: per esempio OG-12, \say{Opere ed impianti di bonifica e protezione ambientale}, può essere indicato in uno qualsiasi dei modi seguenti:
\begin{itemize}
\item Opere Generali 12;
\item Opere Generali di tipo 12;
\item Op.Gen. cat.12;
\item og 12;
\item og12;
\item o.g. 12;
\item og12;
\item o.g.12;
\item og.12;
\item og. 12;
\item og-12;
\item o.g.-12;
\item og.-12;
\item OG 12, "Opere ed impianti di bonifica e protezione ambientale".
\end{itemize}

È altrettanto possibile che la categoria economica, normalmente espressa in numeri romani, si trovi scritta in modi differenti; vediamo il caso della III categoria, di seguito:\begin{itemize}
\item categoria III, con importo fino a euro 1.033.000;
\item cat.III;
\item categoria terza; 
\item cat.III°;
\item cat. 3°.
\end{itemize}
Se si aggiunge che alcuni dei documenti sono stati digitalizzati a partire da fogli stampati e acquisiti con OCR, ci potrebbero essere degli errori di interpretazione; noi di seguito assumeremo di avere a disposizione un documento privo di errori di OCR.


\section{La libreria SpaCy}
Per l'implementazione di una rete neurale abbiamo fatto uso della libreria \textbf{Spacy}, una libreria \text it{open-source} scritta in Python e Cython che implementa funzionalità di Natural Language Processing. Tra i progetti che appartengono al mondo SpaCy vi è la libreria Thinc, che permette di importare modelli statistici da PyTorch, TensorFlow e MXNet\cite{spacyThinc}. Spacy fornisce funzionalità di \textbf{tagger}, \textbf{parser}, \textbf{text categorizer}, \textbf{ner} e permette di articolarli in una pipeline; inoltre rende possibile la configurazione di nuovi componenti e la loro aggiunta alla pipeline. 

\section{Uso di Spacy}
Per l'uso di SpaCy abbiamo dovuto creare gli insiemi di Training, Development e Test.
Le annotazioni gold della ground truth sono state dunque divise in questi tre insiemi, 
rispettivamente aventi il 70\%, il 10 \% e il 20 \% delle annotazioni golden.

\paragraph{Configurazione della pipeline:}
Istruisco SpaCy su quali sono le funzionalità da inserire in pipeline. Nel caso in questione la pipeline deve effettuare la tokenizzazione di elementi testuali della lingua italiana e la loro classificazione come entità. A livello di configurazione questo si traduce in queste righe del file base\_config.cfg:
\begin{lstlisting}[language=Python]
[nlp]
lang = "it"
pipeline = ["tok2vec","ner"]
\end{lstlisting}
Basta poi il seguente comando per ottenere la configurazione completa della pipeline:
\begin{lstlisting}[language=Python]
spacy init fill-config base_config.cfg config.cfg
\end{lstlisting}

\paragraph{Fase di apprendimento:}
La costruzione del modello adopera il le golden labels di training e viene svolta col seguente comando:
\begin{lstlisting}[language=Python]
spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy
  --output ./output
\end{lstlisting}

\paragraph{Debug:}
Data un'entità \textit{E}, avere un numero di esempi di \textit{E} troppo limitato significherebbe dare poca esperienza di \textit{E} al modello.Per questo SpaCy fornisce un comando che controlla il numero di esempi per ogni entità, effettuando al contempo dei controlli ortografici su tutte le labels:
\begin{lstlisting}[language=Python]
python3 -m spacy debug data config.cfg --paths.train ./train.spacy 
  --paths.dev ./dev.spacy
\end{lstlisting}

\paragraph{Valutazione di precision e recall:}
Una volta istruito un modello ed esserci assicurati che le annotazioni che usa sono valide,
possiamo mettere alla prova il modello: sottoponiamo al modello il docbin di test, le cui entità sono già annotate,
e confrontiamo l'output del modello con le annotazioni gold.
Tale confronto viene eseguito da Spacy con il seguente comando:
\begin{lstlisting}[language=Python]
spacy evaluate output/model-best/ test.spacy --displacy-path . --displacy-limit 100  
  --output output.json 
\end{lstlisting}

\paragraph{Uso della rete neurale}
Dopo avere eseguito i passaggi precedenti che hanno permesso la configurazione e l'addestramento della \acrshort{neural-network}
il modello può essere adoperato per estrarre entità da documenti di testo.

\paragraph{Scorer Class}
Lo Scorer è la classe fornita da SpaCy per valutare le performance di un modello annotatore per ogni singola entità basandosi sulle 
annotazioni prodotte da tale modello.
Lo Scorer richiede all'utente della libreria di avere a disposizione l'output del modello annotatore e le gold annotations della Ground Truth.
Per ogni annotazione si crea un oggetto spacy.Span e si crea una lista di Span, che chiameremo labelled\_entities\_span\_list; si potrà poi utilizzare la lista di gold annotations per creare il relativo \textbf{item} che descrive l'annotazione di un documento:

\begin{lstlisting}[language=Python, caption=Esempio di item]
item = Example.from_dict(labelled_entities_span_list, 
                         {"entities": [[start_offset, end_offset, word]
                                      for [start_offset, end_offset, word]
                                      in gold_annots]})
\end{lstlisting}

Si crea un Example per ogni documento annotato e si pongono gli item in una \textbf{item\_list}.
Tutti i dati annotati dal modello annotatore sono ora nella item list ed è dunque possibile invocare 
il task di score vero e proprio:
\begin{lstlisting}[language=Python]
    scores = scorer.score(item_list)
\end{lstlisting}
