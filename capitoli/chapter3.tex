% !TEX encoding = IsoLatin 

% Affinché gli accenti vengano accettati, assicurati che la codifica di questo file
% sia ISO 8859-1

% PER OTTENERE IL PDF, digitare da terminale
% ./makepdfplease
% 


\chapter{Estrazione di entità da testi}
%\chapter[Impiego delle regular expression][]{3. Impiego delle regular expression} %evita la dicitura "capitolo"
In questo capitolo vogliamo focalizzarci sulla \acrfull{named-entity-recognition} e sulle varie possibilità di estrarre 
e classificare informazioni contenute in documenti di testo. L'estrazione di pattern testuali è una pratica consolidata 
nella programmazione tradizionale che fa abbondante uso delle \textbf{regular expression}; tuttavia, le regex soffrono di una
serie di problematiche che le rendono uno strumento poco affidabile se usato da solo. Tali problematiche possono essere arginate e 
risolte se alle regex si affiancano altre tecnologie.
Un altro strumento usato in NER sono le reti neurali o \acrfull{neural-network}, che a differenza delle regex non \say{apprendono}
un pattern testuale con una grammatica regolare, ma con l'uso di un quantitativo massiccio di esempi di dati \textbf{di training} opportunamente classificati, con un approccio che in \acrlong{machine-learning} viene definito \textbf{supervisionato}.
Vedremo che la \acrlong{named-entity-recognition} può avvalersi anche di una tecnologia ibrida che sfrutti in contemporanea strumenti
diversi, tra cui regular expressions, ontologie e reti neurali.
Infine un pattern degno di nota è lo \acrfull{human-in-the-loop}, che permette l'intervento di un revisore umano per apportare correzioni
alle entità estratte dal sistema NER; tale pattern si rivela particolarmente vantaggioso perché abilita il sistema NER ad \textbf{apprendere} le correzioni apportate per migliorare le prestazioni successive.



\section{NER con Regex}
Le regex sono notoriamente un potente strumento software, ma risultano difficilmente leggibili, i loro usi pratici sono documentati poco  e si rivelano poco manutenibili; la comunità dei programmatori ha persino coniato il detto \textit{"Now you have two problems"}\cite{nowTwoProblems}, che esprime come le soluzioni software basate su regex, lungi dall'essere considerate affidabili, creino ulteriori problemi 
a causa della gestione delle regex stesse.
Nello studio \textit{"How to invest my time"} \cite{HowToInvestMyTime} gli autori, ben consapevoli di quanto le regex siano complesse 
ed error-prone, si domandano \textit{fino a che punto} possano essere usate vantaggiosamente;
più in particolare il loro studio si cala nel contesto della Entity Extraction e si pone l'obiettivo di usare al 
meglio le risorse umane, studiando due attività diverse e complementari:
\begin{enumerate}
\item \label{here:att1}lo sviluppo di regex per produrre automaticamente annotazioni dati testuali;
\item \label{here:att2}l'annotazione manuale delle entità contenute nei dati stessi.
\end{enumerate}
Le due attività sono compiute da operatori \textbf{umani}, per cui gli autori con questo studio hanno voluto indagare come
utilizzare al meglio il tempo di un dipendente annotatore e programmatore, provando varie combinazioni delle due attività menzionate.
La regex prodotta al punto ~\ref{here:att1} genera annotazioni dette \textbf{weak labels}, che vanno a costituire il \textbf{training set} della
\acrlong{neural-network}. Al punto  ~\ref{here:att2} l'annotatore può creare annotazioni \textit{ex novo} per ampliare il dataset di training, ma può
anche effettuare attività di \textbf{fine tuning}, correggendo le weak labels che la regex ha generato.
Le due azioni concorrono a formare, addestrare e infine perfezionare una \acrlong{neural-network} e sono state sperimentate con differenti modalità temporali,
creando scenari in cui il tempo è stato speso in diverse proporzioni sulla prima o sulla seconda attività.
I risultati sperimentali di questo studio mostrano che:
\begin{itemize}
\item se il tempo da investire nella EE è poco (inferiore ai 40 minuti), conviene che l'operatore si limiti a produrre una regex;
\item se il tempo è molto (superiore ai 40 minuti), l'operatore potrebbe spendere tutto il tempo a sua disposizione per creare annotazioni con cui istruire la rete neurale;
\item tra i due casi estremi, può convenire che l'operatore umano spenda pochi minuti per creare una regex per un primo setup di rete neurale, per poi aggiungervi annotazioni manuali per farne fine-tuning.
\end{itemize}
Questo approccio che contempla le azioni umane in un sistema automatico da addestrare e perfezionare è detto \textbf{Human In The Loop}.  

\section{Deep Learning con Human-In-The-Loop}
Nel campo della Named Entity Recognition(NER) i metodi di Deep Learning hanno un discreto successo,
perché richiedono un'ingegnerizzazione limitata \cite{ImprovingNE}; allo stesso tempo 
però hanno bisogno di grandi quantità di dati per effettuare il training dei modelli.
Lo studio Improving Named Entity Recognition propone quindi un uso iterativo degli annotatori umani all'interno del sistema Human NERD (dove NERD sta per Named Entity Recognition with Deep Learning).
Questo sistema di \textbf{Human In The Loop} si articola così:
\begin{enumerate}
\item Viene raccolto un dataset T di documenti non annotati;
\item Al sistema Human NERD vengono forniti modelli NER esterni da acquisire; importando tali modelli, Human NERD effettua una prima annotazione dei documenti del dataset T; 
\item Human NERD invia ciascun documento preannotato ad un annotatore umano; poiché si prevede che gli annotatori possano essere in numero maggiore di uno, ogni documento apparterrà esclusivamente ad un annotatore;
l'annotatore prescelto effettua la review delle annotazioni, aggiungendo, rimuovendo o correggendo etichette.
Il risultato della revisione viene inviato al framework;
\item Basandosi sulle correzioni ricevute, Human NERD può aggiornare il modello in maniera incrementale; in alternativa può fare training da zero, istruendo così un modello nuovo.
\item Basandosi sui cambiamenti effettuati, Human NERD calcola il nuovo livello di Accuracy, computa il numero di occorrenze per classe d'entità, calcola il loss basato sulle attività di training e labelling; infine calcola una stima del gain dovuta al miglioramento dell'accuracy.
\end{enumerate}
In definitiva l'approccio \textbf{\acrlong{human-in-the-loop}} è senz'altro promettente per la costruzione di dataset e per il training di modelli \acrshort{named-entity-recognition} sempre più accurati.

\section{Liste di dati da documenti sottoposti a OCR}
Altro interessante contributo al Natural Language Processing è lo studio di Packer et al.\cite{costeffective},
in cui si propone il funzionamento del software ListReader per l'acquisizione di dati da documenti sottoposti ad OCR.
Più nello specifico ListReader acquisisce \textbf{liste} di dati; spetta ad un utente utilizzare l'interfaccia grafica 
di ListReader per compilare un generico form che descriva la struttura dei dati: ad esempio, si pensi ad una lista di persone; ogni elemento della lista dovrà fornire il Nome e il Cognome della persona ed eventualmente altre informazioni anagrafiche; l'utente che osserverà tali dati li userà per creare un form contenente i textbox "Nome", "Cognome", "Data di nascita", "Data di Decesso", etc.
Da questa parziale annotazione ListReader potrà:
\begin{enumerate}
\item popolare un'ontologia con entità e attributi derivanti dal form;
\item indurre una regex per ogni dato identificato, costruendo un wrapper di regex iniziali;
\item generalizzare le regex iniziali con un algoritmo A*, per renderle adeguate a catturare anche dati più complessi;
\item fare \textbf{active learning}: consentire all'utente di modificare il form iniziale quando si presentino dati non aderenti alla struttura descritta dal form.
\end{enumerate}
Infine ListReader risulta più performante degli algoritmi CRF per l'acquisizione di elementi da liste.



